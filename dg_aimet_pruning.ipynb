{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets.folder import default_loader, has_file_allowed_extension\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data as torch_data\n",
    "\n",
    "\n",
    "class CifarDataLoader:\n",
    "    \"\"\"\n",
    "    For loading Validation data from the ImageNet dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_size: int=32, batch_size: int = 128,\n",
    "                 is_training: bool = False, num_workers: int = 2, num_samples_per_class: int = None):\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            # transforms.RandomHorizontalFlip(),\n",
    "            # transforms.RandomCrop(32, padding=4),\n",
    "            transforms.Resize((32,32)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616))\n",
    "        ])\n",
    "        if is_training:\n",
    "            trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "            self._data_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "        else:\n",
    "            testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "            self._data_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    @property\n",
    "    def data_loader(self) -> torch_data.DataLoader:\n",
    "        \"\"\"\n",
    "        Returns the data-loader\n",
    "        \"\"\"\n",
    "        return self._data_loader\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_loader)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# from Examples.torch.utils.image_net_data_loader import ImageNetDataLoader\n",
    "\n",
    "logger = logging.getLogger('Eval')\n",
    "\n",
    "\n",
    "class CifarEvaluator:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._val_data_loader = CifarDataLoader(is_training=False).data_loader\n",
    "\n",
    "    def evaluate(self, model: nn.Module, iterations: int = None, use_cuda: bool = False) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the specified model using the specified number of samples batches from the\n",
    "        validation set.\n",
    "        :param model: The model to be evaluated.\n",
    "        :param iterations: The number of batches to use from the validation set.\n",
    "        :param use_cuda: If True then use a GPU for inference.\n",
    "        :return: The accuracy for the sample with the maximum accuracy.\n",
    "        \"\"\"\n",
    "\n",
    "        device = torch.device('cpu')\n",
    "        if use_cuda:\n",
    "            if torch.cuda.is_available():\n",
    "                \"here\"\n",
    "                device = torch.device('cuda')\n",
    "            else:\n",
    "                logger.error('use_cuda is selected but no cuda device found.')\n",
    "                raise RuntimeError(\"Found no CUDA Device while use_cuda is selected\")\n",
    "\n",
    "        if iterations is None:\n",
    "            logger.info('No value of iteration is provided, running evaluation on complete dataset.')\n",
    "            iterations = len(self._val_data_loader)\n",
    "        if iterations <= 0:\n",
    "            logger.error('Cannot evaluate on %d iterations', iterations)\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        logger.info(\"Evaluating nn.Module for %d iterations with batch_size %d\",\n",
    "                    iterations, self._val_data_loader.batch_size)\n",
    "\n",
    "        model = model.to(device)\n",
    "        model = model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (input_data, target_data) in tqdm(enumerate(self._val_data_loader), total=iterations):\n",
    "                if i == iterations:\n",
    "                    break\n",
    "\n",
    "                inputs_batch = input_data.to(device)\n",
    "                target_batch = target_data.to(device)\n",
    "                predicted_batch = model(inputs_batch)\n",
    "                _, predicted = predicted_batch.max(1)\n",
    "                total += target_batch.size(0)\n",
    "                correct += predicted.eq(target_batch).sum().item()\n",
    "\n",
    "        return 100 * correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "logger = logging.getLogger('Trainer')\n",
    "\n",
    "\n",
    "class CifarTrainer:\n",
    "    \"\"\"\n",
    "    For training a model using the ImageNet dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    # pylint: disable=too-many-arguments\n",
    "    def __init__(self):\n",
    "\n",
    "        self._train_loader = CifarDataLoader(is_training=True).data_loader\n",
    "\n",
    "        self._evaluator = CifarEvaluator()\n",
    "\n",
    "    def _train_loop(self, model: nn.Module, criterion: torch.nn.modules.loss, optimizer: torch.optim,\n",
    "                    max_iterations: int, current_epoch: int, max_epochs: int,\n",
    "                    debug_steps: int = 1000, use_cuda: bool = False):\n",
    "        \"\"\"\n",
    "        Train the specified model using the ImageNet dataset for one epoch.\n",
    "        :param model: The model to train.\n",
    "        :param criterion: loss function to optimize\n",
    "        :param optimizer: optimizer function\n",
    "        :param max_iterations: total number of iterations to train\n",
    "        :param current_epoch: current epoch for model training, used for reporting logs in debug steps\n",
    "        :param max_epochs: total epoch for model training, used for reporting logs in debug steps\n",
    "        :param debug_steps: number of training iterations to report accuracy/loss metrics\n",
    "        :param use_cuda: If True then use GPU device\n",
    "\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # pylint: disable-msg=too-many-locals\n",
    "        device = torch.device('cpu')\n",
    "        if use_cuda:\n",
    "            if torch.cuda.is_available():\n",
    "                device = torch.device('cuda')\n",
    "            else:\n",
    "                logger.error('use_cuda is selected but no cuda device found.')\n",
    "                raise RuntimeError(\"Found no CUDA Device while use_cuda is selected\")\n",
    "\n",
    "        # switch to training mode\n",
    "        model = model.to(device)\n",
    "        model.train()\n",
    "\n",
    "        avg_loss = 0.0\n",
    "\n",
    "        for i, (images, target) in tqdm(enumerate(self._train_loader), total=max_iterations):\n",
    "            if i == max_iterations:\n",
    "                break\n",
    "\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # compute model output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            avg_loss += loss.item()\n",
    "\n",
    "            # compute gradient and do SGD step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % debug_steps == 0:\n",
    "                eval_accuracy = self._evaluator.evaluate(model, use_cuda=use_cuda)\n",
    "                logger.info('Epoch #%d/%d: iteration #%d/%d: Global Avg Loss=%f, Eval Accuracy=%f',\n",
    "                            current_epoch, max_epochs, i, max_iterations,\n",
    "                            avg_loss / i, eval_accuracy)\n",
    "                # switch to training mode after evaluation\n",
    "                model.train()\n",
    "\n",
    "        eval_accuracy = self._evaluator.evaluate(model, use_cuda=use_cuda)\n",
    "        print(\"eval : \", eval_accuracy)\n",
    "        logger.info('At the end of Epoch #%d/%d: Global Avg Loss=%f, Eval Accuracy=%f',\n",
    "                    current_epoch, max_epochs, avg_loss / max_iterations, eval_accuracy)\n",
    "\n",
    "    def train(self, model: nn.Module, max_epochs: int = 20, learning_rate: int = 0.1,\n",
    "              weight_decay: float = 1e-4, decay_rate: float = 0.1, learning_rate_schedule: list = None,\n",
    "              debug_steps: int = 1000, use_cuda: bool = False):\n",
    "        \"\"\"\n",
    "        Train the specified model using the ImageNet dataset.\n",
    "        :param model: The model to train.\n",
    "        :param max_epochs: Maximum number of epochs to use in training.\n",
    "        :param learning_rate: Learning rate\n",
    "        :param weight_decay: Weight decay\n",
    "        :param decay_rate: Multiplicative factor of learning rate decay\n",
    "        :param learning_rate_schedule: Adjust the learning rate based on the number of epochs\n",
    "        :param debug_steps: number of training iterations to report accuracy/loss metrics\n",
    "        :param use_cuda: If True then use GPU device\n",
    "\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        max_iterations = len(self._train_loader)\n",
    "\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay)\n",
    "\n",
    "        if learning_rate_schedule:\n",
    "            learning_rate_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, learning_rate_schedule,\n",
    "                                                                     gamma=decay_rate)\n",
    "\n",
    "        for current_epoch in range(max_epochs):\n",
    "            self._train_loop(model, loss, optimizer, max_iterations, current_epoch + 1, max_epochs, debug_steps,\n",
    "                             use_cuda)\n",
    "\n",
    "            if learning_rate_schedule:\n",
    "                learning_rate_scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from typing import List\n",
    "\n",
    "class CifarDataPipeline:\n",
    "\n",
    "    @staticmethod\n",
    "    def get_val_dataloader() -> torch.utils.data.DataLoader:\n",
    "\n",
    "        data_loader = CifarDataLoader()\n",
    "        return data_loader\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate(model: torch.nn.Module, iterations: int, use_cuda: bool) -> float:\n",
    "        \"\"\"\n",
    "        Given a torch model, evaluates its Top-1 accuracy on the dataset\n",
    "        :param model: the model to evaluate\n",
    "        :param iterations: the number of batches to be used to evaluate the model. A value of 'None' means the model will be\n",
    "                           evaluated on the entire dataset once.\n",
    "        :param use_cuda: whether or not the GPU should be used.\n",
    "        \"\"\"\n",
    "        evaluator = CifarEvaluator()\n",
    "\n",
    "        return evaluator.evaluate(model, iterations=iterations, use_cuda=use_cuda)\n",
    "\n",
    "    @staticmethod\n",
    "    def finetune(model: torch.nn.Module, epochs: int, learning_rate: float, learning_rate_schedule: List, use_cuda: bool):\n",
    "        \"\"\"\n",
    "        Given a torch model, finetunes the model to improve its accuracy\n",
    "        :param model: the model to finetune\n",
    "        :param epochs: The number of epochs used during the finetuning step.\n",
    "        :param learning_rate: The learning rate used during the finetuning step.\n",
    "        :param learning_rate_schedule: The learning rate schedule used during the finetuning step.\n",
    "        :param use_cuda: whether or not the GPU should be used.\n",
    "        \"\"\"\n",
    "        trainer = CifarTrainer()\n",
    "\n",
    "        trainer.train(model, max_epochs=epochs, learning_rate=learning_rate,\n",
    "                      learning_rate_schedule=learning_rate_schedule, use_cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import resnet18\n",
    "model = resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "2024-12-26 01:07:21,063 - Eval - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-26 01:07:21,064 - Eval - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 102.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006194380265247973\n",
      "93.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = CifarDataPipeline.evaluate(model, iterations=None, use_cuda=True)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from decimal import Decimal\n",
    "from aimet_torch.defs import GreedySelectionParameters, ChannelPruningParameters\n",
    "from aimet_common.defs import CompressionScheme, CostMetric\n",
    "\n",
    "greedy_params = GreedySelectionParameters(target_comp_ratio=Decimal(0.7),\n",
    "                                          num_comp_ratio_candidates=3)\n",
    "modules_to_ignore = [model.conv1]\n",
    "auto_params = ChannelPruningParameters.AutoModeParams(greedy_select_params=greedy_params,\n",
    "                                                      modules_to_ignore=modules_to_ignore)\n",
    "data_loader = CifarDataPipeline.get_val_dataloader()\n",
    "params = ChannelPruningParameters(data_loader=data_loader,\n",
    "                                  num_reconstruction_samples=10,\n",
    "                                  allow_custom_downsample_ops=False,\n",
    "                                  mode=ChannelPruningParameters.Mode.auto,\n",
    "                                  params=auto_params)\n",
    "\n",
    "eval_callback = CifarDataPipeline.evaluate\n",
    "eval_iterations = 1\n",
    "compress_scheme = CompressionScheme.channel_pruning\n",
    "cost_metric = CostMetric.mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:05,198 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:05,679 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:06,194 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008884429931640625\n",
      "2024-12-26 01:08:06,375 - CompRatioSelect - INFO - Layer layer1.0.conv1, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:06,375 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:06,868 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:07,383 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008980512619018555\n",
      "2024-12-26 01:08:07,567 - CompRatioSelect - INFO - Layer layer1.0.conv1, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:07,568 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:07,982 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:08,486 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009155035018920898\n",
      "2024-12-26 01:08:08,671 - CompRatioSelect - INFO - Layer layer1.0.conv2, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:08,671 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:09,134 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:09,632 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009193658828735352\n",
      "2024-12-26 01:08:09,820 - CompRatioSelect - INFO - Layer layer1.0.conv2, comp_ratio 0.666667 ==> eval_score=92.968750\n",
      "2024-12-26 01:08:09,820 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:10,308 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:10,811 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009015560150146484\n",
      "2024-12-26 01:08:10,993 - CompRatioSelect - INFO - Layer layer1.1.conv1, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:10,994 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:11,488 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:11,988 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009079217910766602\n",
      "2024-12-26 01:08:12,172 - CompRatioSelect - INFO - Layer layer1.1.conv1, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:12,173 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:12,593 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:13,093 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009200572967529297\n",
      "2024-12-26 01:08:13,277 - CompRatioSelect - INFO - Layer layer1.1.conv2, comp_ratio 0.333333 ==> eval_score=93.750000\n",
      "2024-12-26 01:08:13,278 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:13,735 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:14,233 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009263277053833008\n",
      "2024-12-26 01:08:14,411 - CompRatioSelect - INFO - Layer layer1.1.conv2, comp_ratio 0.666667 ==> eval_score=92.968750\n",
      "2024-12-26 01:08:14,411 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:14,913 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:15,430 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 23.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00909566879272461\n",
      "2024-12-26 01:08:15,619 - CompRatioSelect - INFO - Layer layer2.0.conv1, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:15,619 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:16,143 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:16,656 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009433984756469727\n",
      "2024-12-26 01:08:16,852 - CompRatioSelect - INFO - Layer layer2.0.conv1, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:16,853 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:17,354 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:17,891 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009573221206665039\n",
      "2024-12-26 01:08:18,097 - CompRatioSelect - INFO - Layer layer2.0.conv2, comp_ratio 0.333333 ==> eval_score=93.750000\n",
      "2024-12-26 01:08:18,098 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:18,670 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:19,173 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00904989242553711\n",
      "2024-12-26 01:08:19,359 - CompRatioSelect - INFO - Layer layer2.0.conv2, comp_ratio 0.666667 ==> eval_score=91.406250\n",
      "2024-12-26 01:08:19,360 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:19,776 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:20,266 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009427547454833984\n",
      "2024-12-26 01:08:20,453 - CompRatioSelect - INFO - Layer layer2.0.downsample.0, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:20,454 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:20,856 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:21,346 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009127616882324219\n",
      "2024-12-26 01:08:21,539 - CompRatioSelect - INFO - Layer layer2.0.downsample.0, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:21,539 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:22,234 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:22,738 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009057760238647461\n",
      "2024-12-26 01:08:22,926 - CompRatioSelect - INFO - Layer layer2.1.conv1, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:22,926 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:23,618 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:24,130 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009305715560913086\n",
      "2024-12-26 01:08:24,319 - CompRatioSelect - INFO - Layer layer2.1.conv1, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:24,319 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:25,158 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:25,669 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009363412857055664\n",
      "2024-12-26 01:08:25,872 - CompRatioSelect - INFO - Layer layer2.1.conv2, comp_ratio 0.333333 ==> eval_score=91.406250\n",
      "2024-12-26 01:08:25,873 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:26,465 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:26,977 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009311914443969727\n",
      "2024-12-26 01:08:27,165 - CompRatioSelect - INFO - Layer layer2.1.conv2, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:27,165 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:27,897 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:28,406 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009490489959716797\n",
      "2024-12-26 01:08:28,596 - CompRatioSelect - INFO - Layer layer3.0.conv1, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:28,596 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:29,338 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:29,847 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009378433227539062\n",
      "2024-12-26 01:08:30,049 - CompRatioSelect - INFO - Layer layer3.0.conv1, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:30,050 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:30,670 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:31,184 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009239912033081055\n",
      "2024-12-26 01:08:31,377 - CompRatioSelect - INFO - Layer layer3.0.conv2, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:31,377 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:32,158 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:32,655 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009252309799194336\n",
      "2024-12-26 01:08:32,843 - CompRatioSelect - INFO - Layer layer3.0.conv2, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:32,844 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:33,271 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:33,815 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009088993072509766\n",
      "2024-12-26 01:08:34,003 - CompRatioSelect - INFO - Layer layer3.0.downsample.0, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:34,004 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:34,418 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:34,921 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009049654006958008\n",
      "2024-12-26 01:08:35,127 - CompRatioSelect - INFO - Layer layer3.0.downsample.0, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:35,128 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:36,112 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:36,585 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009107112884521484\n",
      "2024-12-26 01:08:36,768 - CompRatioSelect - INFO - Layer layer3.1.conv1, comp_ratio 0.333333 ==> eval_score=92.968750\n",
      "2024-12-26 01:08:36,769 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:37,794 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:38,267 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008948087692260742\n",
      "2024-12-26 01:08:38,458 - CompRatioSelect - INFO - Layer layer3.1.conv1, comp_ratio 0.666667 ==> eval_score=92.968750\n",
      "2024-12-26 01:08:38,459 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:39,094 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:39,599 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00904703140258789\n",
      "2024-12-26 01:08:39,789 - CompRatioSelect - INFO - Layer layer3.1.conv2, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:39,789 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:40,635 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:41,124 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009272336959838867\n",
      "2024-12-26 01:08:41,312 - CompRatioSelect - INFO - Layer layer3.1.conv2, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:41,312 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:42,272 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:42,772 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009069204330444336\n",
      "2024-12-26 01:08:42,956 - CompRatioSelect - INFO - Layer layer4.0.conv1, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:42,957 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:43,890 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:44,394 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009098529815673828\n",
      "2024-12-26 01:08:44,580 - CompRatioSelect - INFO - Layer layer4.0.conv1, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:44,580 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:45,344 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:45,827 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 24.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009006500244140625\n",
      "2024-12-26 01:08:46,028 - CompRatioSelect - INFO - Layer layer4.0.conv2, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:46,029 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:47,101 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:47,610 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009035110473632812\n",
      "2024-12-26 01:08:47,804 - CompRatioSelect - INFO - Layer layer4.0.conv2, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:47,804 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:48,269 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:48,780 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009011983871459961\n",
      "2024-12-26 01:08:48,972 - CompRatioSelect - INFO - Layer layer4.0.downsample.0, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:48,973 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:49,464 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:49,997 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009097099304199219\n",
      "2024-12-26 01:08:50,194 - CompRatioSelect - INFO - Layer layer4.0.downsample.0, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:50,195 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:51,475 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:51,976 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009024381637573242\n",
      "2024-12-26 01:08:52,172 - CompRatioSelect - INFO - Layer layer4.1.conv1, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:52,172 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:53,372 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:53,880 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009024381637573242\n",
      "2024-12-26 01:08:54,071 - CompRatioSelect - INFO - Layer layer4.1.conv1, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:54,071 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:54,830 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:55,319 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008967876434326172\n",
      "2024-12-26 01:08:55,514 - CompRatioSelect - INFO - Layer layer4.1.conv2, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:55,515 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:08:56,602 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:08:57,100 - Eval - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009177446365356445\n",
      "2024-12-26 01:08:57,286 - CompRatioSelect - INFO - Layer layer4.1.conv2, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-26 01:08:57,287 - CompRatioSelect - INFO - Greedy selection: Saved eval dict to ./data/greedy_selection_eval_scores_dict.pkl\n",
      "2024-12-26 01:08:57,287 - CompRatioSelect - INFO - Greedy selection: overall_min_score=91.406250, overall_max_score=93.750000\n",
      "2024-12-26 01:08:57,287 - CompRatioSelect - INFO - Greedy selection: Original model cost=(Cost: memory=11164352, mac=140186624)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:09:24,607 - CompRatioSelect - INFO - Greedy selection: final choice - comp_ratio=0.459084, score=92.187452\n",
      "2024-12-26 01:09:25,136 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:09:25,613 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:09:26,210 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:09:26,690 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:09:27,283 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:09:27,791 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:09:28,566 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:09:29,238 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:09:30,037 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:09:30,801 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:09:31,316 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:09:32,360 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:09:33,410 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:09:34,585 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:09:35,415 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:09:35,970 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:09:37,341 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:09:38,179 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:09:38,668 - Eval - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-26 01:09:38,668 - Eval - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 97.78it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0062369606162928325\n",
      "Files already downloaded and verified\n",
      "2024-12-26 01:09:40,098 - Eval - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-26 01:09:40,099 - Eval - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 94.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0058783519117138056\n",
      "**********************************************************************************************\n",
      "Compressed Model Statistics\n",
      "Baseline model accuracy: 93.070000, Compressed model accuracy: 34.130000\n",
      "Compression ratio for memory=0.364686, mac=0.459084\n",
      "\n",
      "**********************************************************************************************\n",
      "\n",
      "Per-layer Stats\n",
      "    Name:layer1.0.conv1, compression-ratio: 0.3333333333333333333333333333\n",
      "    Name:layer1.0.conv2, compression-ratio: 0.3333333333333333333333333333\n",
      "    Name:layer1.1.conv1, compression-ratio: 0.3333333333333333333333333333\n",
      "    Name:layer1.1.conv2, compression-ratio: 0.3333333333333333333333333333\n",
      "    Name:layer2.0.conv1, compression-ratio: 0.3333333333333333333333333333\n",
      "    Name:layer2.0.conv2, compression-ratio: None\n",
      "    Name:layer2.0.downsample.0, compression-ratio: 0.3333333333333333333333333333\n",
      "    Name:layer2.1.conv1, compression-ratio: 0.3333333333333333333333333333\n",
      "    Name:layer2.1.conv2, compression-ratio: 0.6666666666666666666666666666\n",
      "    Name:layer3.0.conv1, compression-ratio: 0.3333333333333333333333333333\n",
      "    Name:layer3.0.conv2, compression-ratio: 0.3333333333333333333333333333\n",
      "    Name:layer3.0.downsample.0, compression-ratio: 0.3333333333333333333333333333\n",
      "    Name:layer3.1.conv1, compression-ratio: 0.3333333333333333333333333333\n",
      "    Name:layer3.1.conv2, compression-ratio: 0.3333333333333333333333333333\n",
      "    Name:layer4.0.conv1, compression-ratio: 0.3333333333333333333333333333\n",
      "    Name:layer4.0.conv2, compression-ratio: 0.3333333333333333333333333333\n",
      "    Name:layer4.0.downsample.0, compression-ratio: 0.3333333333333333333333333333\n",
      "    Name:layer4.1.conv1, compression-ratio: 0.3333333333333333333333333333\n",
      "    Name:layer4.1.conv2, compression-ratio: 0.3333333333333333333333333333\n",
      "\n",
      "**********************************************************************************************\n",
      "\n",
      "Greedy Eval Dict\n",
      "    Layer: layer1.0.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer1.0.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.96875\n",
      "    Layer: layer1.1.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer1.1.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=93.75\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.96875\n",
      "    Layer: layer2.0.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer2.0.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=93.75\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=91.40625\n",
      "    Layer: layer2.0.downsample.0\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer2.1.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer2.1.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=91.40625\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer3.0.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer3.0.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer3.0.downsample.0\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer3.1.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.96875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.96875\n",
      "    Layer: layer3.1.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer4.0.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer4.0.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer4.0.downsample.0\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer4.1.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer4.1.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "\n",
      "**********************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from aimet_torch.compress import ModelCompressor\n",
    "compressed_model, comp_stats = ModelCompressor.compress_model(model=model,\n",
    "                                                              eval_callback=eval_callback,\n",
    "                                                              eval_iterations=eval_iterations,\n",
    "                                                              input_shape=(1, 3, 32, 32),\n",
    "                                                              compress_scheme=compress_scheme,\n",
    "                                                              cost_metric=cost_metric,\n",
    "                                                              parameters=params)\n",
    "\n",
    "print(comp_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "2024-12-26 01:09:41,567 - Eval - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-26 01:09:41,568 - Eval - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 96.65it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006051205381562438\n",
      "34.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = CifarDataPipeline.evaluate(compressed_model, iterations=None, use_cuda=True)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 55.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:09:50,862 - Eval - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-26 01:09:50,863 - Eval - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 97.55it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005133218403103985\n",
      "eval :  77.72\n",
      "2024-12-26 01:09:51,822 - Eval - INFO - At the end of Epoch #1/10: Global Avg Loss=0.862478, Eval Accuracy=77.720000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:07<00:00, 54.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:09:59,159 - Eval - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-26 01:09:59,159 - Eval - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 94.83it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005027777032007145\n",
      "eval :  80.44\n",
      "2024-12-26 01:10:00,128 - Eval - INFO - At the end of Epoch #2/10: Global Avg Loss=0.485165, Eval Accuracy=80.440000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:07<00:00, 55.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:10:07,281 - Eval - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-26 01:10:07,281 - Eval - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 96.70it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004970562608936165\n",
      "eval :  82.58\n",
      "2024-12-26 01:10:08,237 - Eval - INFO - At the end of Epoch #3/10: Global Avg Loss=0.358796, Eval Accuracy=82.580000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:07<00:00, 53.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:10:15,664 - Eval - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-26 01:10:15,665 - Eval - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 96.67it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005023120324822921\n",
      "eval :  81.55\n",
      "2024-12-26 01:10:16,619 - Eval - INFO - At the end of Epoch #4/10: Global Avg Loss=0.272304, Eval Accuracy=81.550000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:07<00:00, 54.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:10:23,970 - Eval - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-26 01:10:23,970 - Eval - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 100.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005126147330561771\n",
      "eval :  82.33\n",
      "2024-12-26 01:10:24,885 - Eval - INFO - At the end of Epoch #5/10: Global Avg Loss=0.200992, Eval Accuracy=82.330000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:07<00:00, 54.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:10:32,145 - Eval - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-26 01:10:32,145 - Eval - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 94.87it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005082555964023252\n",
      "eval :  87.39\n",
      "2024-12-26 01:10:33,109 - Eval - INFO - At the end of Epoch #6/10: Global Avg Loss=0.096214, Eval Accuracy=87.390000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:07<00:00, 55.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:10:40,267 - Eval - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-26 01:10:40,267 - Eval - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 95.40it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005069074751455573\n",
      "eval :  87.59\n",
      "2024-12-26 01:10:41,229 - Eval - INFO - At the end of Epoch #7/10: Global Avg Loss=0.061288, Eval Accuracy=87.590000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:07<00:00, 53.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:10:48,641 - Eval - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-26 01:10:48,641 - Eval - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 97.95it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005227070820482471\n",
      "eval :  87.51\n",
      "2024-12-26 01:10:49,588 - Eval - INFO - At the end of Epoch #8/10: Global Avg Loss=0.046557, Eval Accuracy=87.510000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:07<00:00, 53.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:10:56,976 - Eval - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-26 01:10:56,977 - Eval - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 97.01it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0050340785255915\n",
      "eval :  87.7\n",
      "2024-12-26 01:10:57,922 - Eval - INFO - At the end of Epoch #9/10: Global Avg Loss=0.038059, Eval Accuracy=87.700000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:07<00:00, 54.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-26 01:11:05,280 - Eval - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-26 01:11:05,281 - Eval - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 97.55it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005044475386414347\n",
      "eval :  87.63\n",
      "2024-12-26 01:11:06,231 - Eval - INFO - At the end of Epoch #10/10: Global Avg Loss=0.032650, Eval Accuracy=87.630000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CifarDataPipeline.finetune(compressed_model, epochs=10, learning_rate=10e-4, learning_rate_schedule=[5, 10],\n",
    "                              use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "2024-12-26 01:11:06,709 - Eval - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-26 01:11:06,709 - Eval - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 97.88it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005935035174406028\n",
      "87.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = CifarDataPipeline.evaluate(compressed_model, iterations=None, use_cuda=True)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./output/', exist_ok=True)\n",
    "torch.save(compressed_model, './output/finetuned_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
