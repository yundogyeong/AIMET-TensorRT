{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 데이터 변환 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616))\n",
    "])\n",
    "\n",
    "# 데이터 로더 설정\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = cifar100_resnet56(pretrained=True)\n",
    "# model = model.to(device)\n",
    "from mobilenetv2 import mobilenet_v2\n",
    "model = mobilenet_v2(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01758119124400465\n",
      "Accuracy on test set: 93.91%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "correct = 0\n",
    "total = 0\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        torch.cuda.synchronize()\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        start = time.time()\n",
    "        outputs = model(inputs)\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        results.append(end-start)\n",
    "\n",
    "infer_time = np.mean(results)\n",
    "print(infer_time)\n",
    "print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aimet_torch.v2.batch_norm_fold import fold_all_batch_norms\n",
    "\n",
    "_ = fold_all_batch_norms(model, input_shapes=(1, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:05:37,657 - Quant - INFO - No config file provided, defaulting to config file at /usr/local/lib/python3.10/dist-packages/aimet_common/quantsim_config/default_config.json\n",
      "2024-12-23 06:05:37,675 - Quant - INFO - Unsupported op type Squeeze\n",
      "2024-12-23 06:05:37,675 - Quant - INFO - Unsupported op type Mean\n",
      "2024-12-23 06:05:37,677 - Quant - INFO - Selecting DefaultOpInstanceConfigGenerator to compute the specialized config. hw_version:default\n"
     ]
    }
   ],
   "source": [
    "from aimet_common.defs import QuantScheme\n",
    "from aimet_torch.v1.quantsim import QuantizationSimModel\n",
    "\n",
    "dummy_input = torch.rand(1, 3, 32, 32)    # Shape for each ImageNet sample is (3 channels) x (224 height) x (224 width)\n",
    "\n",
    "dummy_input = dummy_input.cuda()\n",
    "\n",
    "sim = QuantizationSimModel(model=model,\n",
    "                           quant_scheme=QuantScheme.post_training_tf_enhanced,\n",
    "                           dummy_input=dummy_input,\n",
    "                           default_output_bw=8,\n",
    "                           default_param_bw=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5548770970936063\n",
      "Accuracy on test set: 90.84%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "correct = 0\n",
    "total = 0\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        torch.cuda.synchronize()\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        start = time.time()\n",
    "        outputs = sim.model(inputs)\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        results.append(end-start)\n",
    "\n",
    "infer_time = np.mean(results)\n",
    "print(infer_time)\n",
    "print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_calibration_data(sim_model, use_cuda):\n",
    "    data_loader = testloader\n",
    "    batch_size = data_loader.batch_size\n",
    "\n",
    "    if use_cuda:\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    sim_model.eval()\n",
    "    samples = 1000\n",
    "\n",
    "    batch_cntr = 0\n",
    "    with torch.no_grad():\n",
    "        for input_data, target_data in data_loader:\n",
    "\n",
    "            inputs_batch = input_data.to(device)\n",
    "            sim_model(inputs_batch)\n",
    "\n",
    "            batch_cntr += 1\n",
    "            if (batch_cntr * batch_size) > samples:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.compute_encodings(forward_pass_callback=pass_calibration_data,\n",
    "                      forward_pass_callback_args=use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016245310819601712\n",
      "Accuracy on test set: 90.76%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "correct = 0\n",
    "total = 0\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        torch.cuda.synchronize()\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        start = time.time()\n",
    "        outputs = sim.model(inputs)\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        results.append(end-start)\n",
    "\n",
    "infer_time = np.mean(results)\n",
    "print(infer_time)\n",
    "print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:06:59,835 - Quant - INFO - No config file provided, defaulting to config file at /usr/local/lib/python3.10/dist-packages/aimet_common/quantsim_config/default_config.json\n",
      "2024-12-23 06:06:59,853 - Quant - INFO - Unsupported op type Squeeze\n",
      "2024-12-23 06:06:59,853 - Quant - INFO - Unsupported op type Mean\n",
      "2024-12-23 06:06:59,856 - Quant - INFO - Selecting DefaultOpInstanceConfigGenerator to compute the specialized config. hw_version:default\n",
      "2024-12-23 06:07:00,458 - Utils - INFO - Caching 1 batches from data loader at path location: /tmp/tmpztxrh4s_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:00,469 - Quant - INFO - Started Optimizing weight rounding of module: features.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:01,178 - Quant - INFO - Started Optimizing weight rounding of module: features.1.conv.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:01,864 - Quant - INFO - Started Optimizing weight rounding of module: features.1.conv.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:02,454 - Quant - INFO - Started Optimizing weight rounding of module: features.2.conv.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:02,620 - Quant - INFO - Started Optimizing weight rounding of module: features.2.conv.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:03,298 - Quant - INFO - Started Optimizing weight rounding of module: features.2.conv.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:04,071 - Quant - INFO - Started Optimizing weight rounding of module: features.3.conv.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:04,752 - Quant - INFO - Started Optimizing weight rounding of module: features.3.conv.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:05,492 - Quant - INFO - Started Optimizing weight rounding of module: features.3.conv.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:06,197 - Quant - INFO - Started Optimizing weight rounding of module: features.4.conv.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:06,910 - Quant - INFO - Started Optimizing weight rounding of module: features.4.conv.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:07,642 - Quant - INFO - Started Optimizing weight rounding of module: features.4.conv.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:08,406 - Quant - INFO - Started Optimizing weight rounding of module: features.5.conv.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:09,106 - Quant - INFO - Started Optimizing weight rounding of module: features.5.conv.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:09,837 - Quant - INFO - Started Optimizing weight rounding of module: features.5.conv.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:10,548 - Quant - INFO - Started Optimizing weight rounding of module: features.6.conv.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:11,229 - Quant - INFO - Started Optimizing weight rounding of module: features.6.conv.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:11,870 - Quant - INFO - Started Optimizing weight rounding of module: features.6.conv.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:12,032 - Quant - INFO - Started Optimizing weight rounding of module: features.7.conv.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:12,707 - Quant - INFO - Started Optimizing weight rounding of module: features.7.conv.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:12,866 - Quant - INFO - Started Optimizing weight rounding of module: features.7.conv.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:13,476 - Quant - INFO - Started Optimizing weight rounding of module: features.8.conv.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:14,180 - Quant - INFO - Started Optimizing weight rounding of module: features.8.conv.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:14,887 - Quant - INFO - Started Optimizing weight rounding of module: features.8.conv.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:15,560 - Quant - INFO - Started Optimizing weight rounding of module: features.9.conv.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:15,720 - Quant - INFO - Started Optimizing weight rounding of module: features.9.conv.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:16,353 - Quant - INFO - Started Optimizing weight rounding of module: features.9.conv.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:17,044 - Quant - INFO - Started Optimizing weight rounding of module: features.10.conv.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:17,794 - Quant - INFO - Started Optimizing weight rounding of module: features.10.conv.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:18,494 - Quant - INFO - Started Optimizing weight rounding of module: features.10.conv.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:19,234 - Quant - INFO - Started Optimizing weight rounding of module: features.11.conv.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:19,921 - Quant - INFO - Started Optimizing weight rounding of module: features.11.conv.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:20,528 - Quant - INFO - Started Optimizing weight rounding of module: features.11.conv.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:20,709 - Quant - INFO - Started Optimizing weight rounding of module: features.12.conv.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:21,401 - Quant - INFO - Started Optimizing weight rounding of module: features.12.conv.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:22,101 - Quant - INFO - Started Optimizing weight rounding of module: features.12.conv.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:22,850 - Quant - INFO - Started Optimizing weight rounding of module: features.13.conv.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:23,506 - Quant - INFO - Started Optimizing weight rounding of module: features.13.conv.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:24,141 - Quant - INFO - Started Optimizing weight rounding of module: features.13.conv.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:24,333 - Quant - INFO - Started Optimizing weight rounding of module: features.14.conv.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:25,039 - Quant - INFO - Started Optimizing weight rounding of module: features.14.conv.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:25,716 - Quant - INFO - Started Optimizing weight rounding of module: features.14.conv.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:26,307 - Quant - INFO - Started Optimizing weight rounding of module: features.15.conv.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:26,514 - Quant - INFO - Started Optimizing weight rounding of module: features.15.conv.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:27,195 - Quant - INFO - Started Optimizing weight rounding of module: features.15.conv.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:27,894 - Quant - INFO - Started Optimizing weight rounding of module: features.16.conv.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:28,614 - Quant - INFO - Started Optimizing weight rounding of module: features.16.conv.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:29,343 - Quant - INFO - Started Optimizing weight rounding of module: features.16.conv.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:30,055 - Quant - INFO - Started Optimizing weight rounding of module: features.17.conv.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:30,777 - Quant - INFO - Started Optimizing weight rounding of module: features.17.conv.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:31,490 - Quant - INFO - Started Optimizing weight rounding of module: features.17.conv.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:32,219 - Quant - INFO - Started Optimizing weight rounding of module: features.18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:32,944 - Quant - INFO - Started Optimizing weight rounding of module: classifier.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:33<00:00,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:33,650 - Quant - INFO - Completed Adarounding Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from aimet_torch.v1.adaround.adaround_weight import Adaround, AdaroundParameters\n",
    "import os\n",
    "\n",
    "data_loader = testloader\n",
    "params = AdaroundParameters(data_loader=data_loader, num_batches=1, default_num_iterations=64)\n",
    "\n",
    "dummy_input = torch.rand(1, 3, 32, 32)\n",
    "if use_cuda:\n",
    "    dummy_input = dummy_input.cuda()\n",
    "\n",
    "os.makedirs('./output/', exist_ok=True)\n",
    "ada_model = Adaround.apply_adaround(model, dummy_input, params,\n",
    "                                    path=\"output\", \n",
    "                                    filename_prefix='adaround', \n",
    "                                    default_param_bw=4,\n",
    "                                    default_quant_scheme=QuantScheme.post_training_tf_enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:07:36,770 - Quant - INFO - No config file provided, defaulting to config file at /usr/local/lib/python3.10/dist-packages/aimet_common/quantsim_config/default_config.json\n",
      "2024-12-23 06:07:36,788 - Quant - INFO - Unsupported op type Squeeze\n",
      "2024-12-23 06:07:36,788 - Quant - INFO - Unsupported op type Mean\n",
      "2024-12-23 06:07:36,791 - Quant - INFO - Selecting DefaultOpInstanceConfigGenerator to compute the specialized config. hw_version:default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2767759/1299832713.py:7: DeprecationWarning: \u001b[31;21mQuantizationSimModel.set_and_freeze_param_encodings will be deprecated soon in the later versions. Use QuantizationSimModel.load_encodings instead.\u001b[0m\n",
      "  sim.set_and_freeze_param_encodings(encoding_path=os.path.join(\"output\", 'adaround.encodings'))\n"
     ]
    }
   ],
   "source": [
    "sim = QuantizationSimModel(model=ada_model,\n",
    "                           dummy_input=dummy_input,\n",
    "                           quant_scheme=QuantScheme.post_training_tf_enhanced,\n",
    "                           default_output_bw=8, \n",
    "                           default_param_bw=4)\n",
    "\n",
    "sim.set_and_freeze_param_encodings(encoding_path=os.path.join(\"output\", 'adaround.encodings'))\n",
    "\n",
    "sim.compute_encodings(forward_pass_callback=pass_calibration_data,\n",
    "                      forward_pass_callback_args=use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016973688632627076\n",
      "Accuracy on test set: 92.51%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "correct = 0\n",
    "total = 0\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        torch.cuda.synchronize()\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        start = time.time()\n",
    "        outputs = sim.model(inputs)\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        results.append(end-start)\n",
    "\n",
    "infer_time = np.mean(results)\n",
    "print(infer_time)\n",
    "print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
