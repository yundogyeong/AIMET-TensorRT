{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets.folder import default_loader, has_file_allowed_extension\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data as torch_data\n",
    "\n",
    "\n",
    "class CifarDataLoader:\n",
    "    \"\"\"\n",
    "    For loading Validation data from the ImageNet dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_size: int=32, batch_size: int = 128,\n",
    "                 is_training: bool = False, num_workers: int = 2, num_samples_per_class: int = None):\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            # transforms.RandomHorizontalFlip(),\n",
    "            # transforms.RandomCrop(32, padding=4),\n",
    "            transforms.Resize((32,32)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616))\n",
    "        ])\n",
    "        if is_training:\n",
    "            trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "            self._data_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "        else:\n",
    "            testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "            self._data_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    @property\n",
    "    def data_loader(self) -> torch_data.DataLoader:\n",
    "        \"\"\"\n",
    "        Returns the data-loader\n",
    "        \"\"\"\n",
    "        return self._data_loader\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_loader)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# from Examples.torch.utils.image_net_data_loader import ImageNetDataLoader\n",
    "\n",
    "logger = logging.getLogger('Eval')\n",
    "\n",
    "\n",
    "class CifarEvaluator:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._val_data_loader = CifarDataLoader(is_training=False).data_loader\n",
    "\n",
    "    def evaluate(self, model: nn.Module, iterations: int = None, use_cuda: bool = False) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the specified model using the specified number of samples batches from the\n",
    "        validation set.\n",
    "        :param model: The model to be evaluated.\n",
    "        :param iterations: The number of batches to use from the validation set.\n",
    "        :param use_cuda: If True then use a GPU for inference.\n",
    "        :return: The accuracy for the sample with the maximum accuracy.\n",
    "        \"\"\"\n",
    "\n",
    "        device = torch.device('cpu')\n",
    "        if use_cuda:\n",
    "            if torch.cuda.is_available():\n",
    "                \"here\"\n",
    "                device = torch.device('cuda')\n",
    "            else:\n",
    "                logger.error('use_cuda is selected but no cuda device found.')\n",
    "                raise RuntimeError(\"Found no CUDA Device while use_cuda is selected\")\n",
    "\n",
    "        if iterations is None:\n",
    "            logger.info('No value of iteration is provided, running evaluation on complete dataset.')\n",
    "            iterations = len(self._val_data_loader)\n",
    "        if iterations <= 0:\n",
    "            logger.error('Cannot evaluate on %d iterations', iterations)\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        logger.info(\"Evaluating nn.Module for %d iterations with batch_size %d\",\n",
    "                    iterations, self._val_data_loader.batch_size)\n",
    "\n",
    "        model = model.to(device)\n",
    "        model = model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (input_data, target_data) in tqdm(enumerate(self._val_data_loader), total=iterations):\n",
    "                if i == iterations:\n",
    "                    break\n",
    "\n",
    "                inputs_batch = input_data.to(device)\n",
    "                target_batch = target_data.to(device)\n",
    "                predicted_batch = model(inputs_batch)\n",
    "                _, predicted = predicted_batch.max(1)\n",
    "                total += target_batch.size(0)\n",
    "                correct += predicted.eq(target_batch).sum().item()\n",
    "\n",
    "        return 100 * correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "logger = logging.getLogger('Trainer')\n",
    "\n",
    "\n",
    "class CifarTrainer:\n",
    "    \"\"\"\n",
    "    For training a model using the ImageNet dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    # pylint: disable=too-many-arguments\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        :param images_dir: The path to the data directory\n",
    "        :param image_size: The length of the image\n",
    "        :param batch_size: The batch size to use for training and validation\n",
    "        :param num_workers: Indiicates to the data loader how many sub-processes to use for data loading.\n",
    "        :param num_train_samples_per_class: Number of samples to use per class.\n",
    "        \"\"\"\n",
    "\n",
    "        self._train_loader = CifarDataLoader(is_training=True).data_loader\n",
    "\n",
    "        self._evaluator = CifarEvaluator()\n",
    "\n",
    "    def _train_loop(self, model: nn.Module, criterion: torch.nn.modules.loss, optimizer: torch.optim,\n",
    "                    max_iterations: int, current_epoch: int, max_epochs: int,\n",
    "                    debug_steps: int = 1000, use_cuda: bool = False):\n",
    "        \"\"\"\n",
    "        Train the specified model using the ImageNet dataset for one epoch.\n",
    "        :param model: The model to train.\n",
    "        :param criterion: loss function to optimize\n",
    "        :param optimizer: optimizer function\n",
    "        :param max_iterations: total number of iterations to train\n",
    "        :param current_epoch: current epoch for model training, used for reporting logs in debug steps\n",
    "        :param max_epochs: total epoch for model training, used for reporting logs in debug steps\n",
    "        :param debug_steps: number of training iterations to report accuracy/loss metrics\n",
    "        :param use_cuda: If True then use GPU device\n",
    "\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # pylint: disable-msg=too-many-locals\n",
    "        device = torch.device('cpu')\n",
    "        if use_cuda:\n",
    "            if torch.cuda.is_available():\n",
    "                device = torch.device('cuda')\n",
    "            else:\n",
    "                logger.error('use_cuda is selected but no cuda device found.')\n",
    "                raise RuntimeError(\"Found no CUDA Device while use_cuda is selected\")\n",
    "\n",
    "        # switch to training mode\n",
    "        model = model.to(device)\n",
    "        model.train()\n",
    "\n",
    "        avg_loss = 0.0\n",
    "\n",
    "        for i, (images, target) in tqdm(enumerate(self._train_loader), total=max_iterations):\n",
    "            if i == max_iterations:\n",
    "                break\n",
    "\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # compute model output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            avg_loss += loss.item()\n",
    "\n",
    "            # compute gradient and do SGD step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % debug_steps == 0:\n",
    "                eval_accuracy = self._evaluator.evaluate(model, use_cuda=use_cuda)\n",
    "                logger.info('Epoch #%d/%d: iteration #%d/%d: Global Avg Loss=%f, Eval Accuracy=%f',\n",
    "                            current_epoch, max_epochs, i, max_iterations,\n",
    "                            avg_loss / i, eval_accuracy)\n",
    "                # switch to training mode after evaluation\n",
    "                model.train()\n",
    "\n",
    "        eval_accuracy = self._evaluator.evaluate(model, use_cuda=use_cuda)\n",
    "        print(\"eval : \", eval_accuracy)\n",
    "        logger.info('At the end of Epoch #%d/%d: Global Avg Loss=%f, Eval Accuracy=%f',\n",
    "                    current_epoch, max_epochs, avg_loss / max_iterations, eval_accuracy)\n",
    "\n",
    "    def train(self, model: nn.Module, max_epochs: int = 20, learning_rate: int = 0.1,\n",
    "              weight_decay: float = 1e-4, decay_rate: float = 0.1, learning_rate_schedule: list = None,\n",
    "              debug_steps: int = 1000, use_cuda: bool = False):\n",
    "        \"\"\"\n",
    "        Train the specified model using the ImageNet dataset.\n",
    "        :param model: The model to train.\n",
    "        :param max_epochs: Maximum number of epochs to use in training.\n",
    "        :param learning_rate: Learning rate\n",
    "        :param weight_decay: Weight decay\n",
    "        :param decay_rate: Multiplicative factor of learning rate decay\n",
    "        :param learning_rate_schedule: Adjust the learning rate based on the number of epochs\n",
    "        :param debug_steps: number of training iterations to report accuracy/loss metrics\n",
    "        :param use_cuda: If True then use GPU device\n",
    "\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        max_iterations = len(self._train_loader)\n",
    "\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay)\n",
    "\n",
    "        if learning_rate_schedule:\n",
    "            learning_rate_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, learning_rate_schedule,\n",
    "                                                                     gamma=decay_rate)\n",
    "\n",
    "        for current_epoch in range(max_epochs):\n",
    "            self._train_loop(model, loss, optimizer, max_iterations, current_epoch + 1, max_epochs, debug_steps,\n",
    "                             use_cuda)\n",
    "\n",
    "            if learning_rate_schedule:\n",
    "                learning_rate_scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from typing import List\n",
    "\n",
    "class CifarDataPipeline:\n",
    "\n",
    "    @staticmethod\n",
    "    def get_val_dataloader() -> torch.utils.data.DataLoader:\n",
    "\n",
    "        data_loader = CifarDataLoader()\n",
    "        return data_loader\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate(model: torch.nn.Module, iterations: int, use_cuda: bool) -> float:\n",
    "        \"\"\"\n",
    "        Given a torch model, evaluates its Top-1 accuracy on the dataset\n",
    "        :param model: the model to evaluate\n",
    "        :param iterations: the number of batches to be used to evaluate the model. A value of 'None' means the model will be\n",
    "                           evaluated on the entire dataset once.\n",
    "        :param use_cuda: whether or not the GPU should be used.\n",
    "        \"\"\"\n",
    "        evaluator = CifarEvaluator()\n",
    "\n",
    "        return evaluator.evaluate(model, iterations=iterations, use_cuda=use_cuda)\n",
    "\n",
    "    @staticmethod\n",
    "    def finetune(model: torch.nn.Module, epochs: int, learning_rate: float, learning_rate_schedule: List, use_cuda: bool):\n",
    "        \"\"\"\n",
    "        Given a torch model, finetunes the model to improve its accuracy\n",
    "        :param model: the model to finetune\n",
    "        :param epochs: The number of epochs used during the finetuning step.\n",
    "        :param learning_rate: The learning rate used during the finetuning step.\n",
    "        :param learning_rate_schedule: The learning rate schedule used during the finetuning step.\n",
    "        :param use_cuda: whether or not the GPU should be used.\n",
    "        \"\"\"\n",
    "        trainer = CifarTrainer()\n",
    "\n",
    "        trainer.train(model, max_epochs=epochs, learning_rate=learning_rate,\n",
    "                      learning_rate_schedule=learning_rate_schedule, use_cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import resnet18\n",
    "model = resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:16<00:00, 10323568.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 55.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = CifarDataPipeline.evaluate(model, iterations=None, use_cuda=True)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from decimal import Decimal\n",
    "from aimet_torch.defs import GreedySelectionParameters, ChannelPruningParameters\n",
    "from aimet_common.defs import CompressionScheme, CostMetric\n",
    "\n",
    "greedy_params = GreedySelectionParameters(target_comp_ratio=Decimal(0.9),\n",
    "                                          num_comp_ratio_candidates=3)\n",
    "modules_to_ignore = [model.conv1]\n",
    "auto_params = ChannelPruningParameters.AutoModeParams(greedy_select_params=greedy_params,\n",
    "                                                      modules_to_ignore=modules_to_ignore)\n",
    "data_loader = CifarDataPipeline.get_val_dataloader()\n",
    "params = ChannelPruningParameters(data_loader=data_loader,\n",
    "                                  num_reconstruction_samples=10,\n",
    "                                  allow_custom_downsample_ops=False,\n",
    "                                  mode=ChannelPruningParameters.Mode.auto,\n",
    "                                  params=auto_params)\n",
    "\n",
    "eval_callback = CifarDataPipeline.evaluate\n",
    "eval_iterations = 1\n",
    "compress_scheme = CompressionScheme.channel_pruning\n",
    "cost_metric = CostMetric.mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:10,410 - root - INFO - AIMET\n"
     ]
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.2.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.2.min.js\", \"https://cdn.holoviz.org/panel/1.3.8/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1002'>\n",
       "  <div id=\"d7624cee-84df-4ed4-96bc-021fcf594eb9\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"2050a287-b1e1-4815-9225-fb735d2fd95a\":{\"version\":\"3.2.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1002\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1003\",\"attributes\":{\"plot_id\":\"p1002\",\"comm_id\":\"7cc33417398a4c8981840f40b07d73c5\",\"client_comm_id\":\"84d8d6d089084c5594b089e9e13c26c0\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"2050a287-b1e1-4815-9225-fb735d2fd95a\",\"roots\":{\"p1002\":\"d7624cee-84df-4ed4-96bc-021fcf594eb9\"},\"root_ids\":[\"p1002\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1002"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:15,455 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:17,071 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:17,585 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:17,727 - CompRatioSelect - INFO - Layer layer1.0.conv1, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-23 05:57:17,728 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:18,604 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:19,136 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:19,276 - CompRatioSelect - INFO - Layer layer1.0.conv1, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-23 05:57:19,277 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:19,870 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:20,378 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:20,550 - CompRatioSelect - INFO - Layer layer1.0.conv2, comp_ratio 0.333333 ==> eval_score=96.093750\n",
      "2024-12-23 05:57:20,551 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:21,377 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:21,877 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:22,028 - CompRatioSelect - INFO - Layer layer1.0.conv2, comp_ratio 0.666667 ==> eval_score=92.968750\n",
      "2024-12-23 05:57:22,028 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:22,548 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:23,083 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:23,232 - CompRatioSelect - INFO - Layer layer1.1.conv1, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-23 05:57:23,233 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:23,749 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:24,280 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:24,852 - CompRatioSelect - INFO - Layer layer1.1.conv1, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-23 05:57:24,852 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:25,599 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:26,112 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:26,273 - CompRatioSelect - INFO - Layer layer1.1.conv2, comp_ratio 0.333333 ==> eval_score=92.968750\n",
      "2024-12-23 05:57:26,274 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:26,683 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:27,184 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:27,335 - CompRatioSelect - INFO - Layer layer1.1.conv2, comp_ratio 0.666667 ==> eval_score=92.968750\n",
      "2024-12-23 05:57:27,336 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:27,822 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:28,370 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:28,516 - CompRatioSelect - INFO - Layer layer2.0.conv1, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-23 05:57:28,516 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:29,353 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:29,943 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:30,587 - CompRatioSelect - INFO - Layer layer2.0.conv1, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-23 05:57:30,588 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:31,146 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:31,692 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:31,847 - CompRatioSelect - INFO - Layer layer2.0.conv2, comp_ratio 0.333333 ==> eval_score=93.750000\n",
      "2024-12-23 05:57:31,847 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:32,517 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:33,064 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:33,223 - CompRatioSelect - INFO - Layer layer2.0.conv2, comp_ratio 0.666667 ==> eval_score=91.406250\n",
      "2024-12-23 05:57:33,223 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:33,581 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:34,116 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:34,269 - CompRatioSelect - INFO - Layer layer2.0.downsample.0, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-23 05:57:34,270 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:34,892 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:35,395 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:35,544 - CompRatioSelect - INFO - Layer layer2.0.downsample.0, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-23 05:57:35,544 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:36,291 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:36,817 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:37,010 - CompRatioSelect - INFO - Layer layer2.1.conv1, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-23 05:57:37,011 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:38,279 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:38,791 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:39,147 - CompRatioSelect - INFO - Layer layer2.1.conv1, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-23 05:57:39,147 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:39,673 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:40,230 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 35.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:40,386 - CompRatioSelect - INFO - Layer layer2.1.conv2, comp_ratio 0.333333 ==> eval_score=90.625000\n",
      "2024-12-23 05:57:40,387 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:40,994 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:41,543 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:41,700 - CompRatioSelect - INFO - Layer layer2.1.conv2, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-23 05:57:41,700 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:42,592 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:43,119 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:43,422 - CompRatioSelect - INFO - Layer layer3.0.conv1, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-23 05:57:43,423 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:44,877 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:45,405 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:45,560 - CompRatioSelect - INFO - Layer layer3.0.conv1, comp_ratio 0.666667 ==> eval_score=92.968750\n",
      "2024-12-23 05:57:45,561 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:46,241 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:46,801 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:47,007 - CompRatioSelect - INFO - Layer layer3.0.conv2, comp_ratio 0.333333 ==> eval_score=91.406250\n",
      "2024-12-23 05:57:47,008 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:48,309 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:48,809 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:49,147 - CompRatioSelect - INFO - Layer layer3.0.conv2, comp_ratio 0.666667 ==> eval_score=91.406250\n",
      "2024-12-23 05:57:49,148 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:49,537 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:50,069 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:50,222 - CompRatioSelect - INFO - Layer layer3.0.downsample.0, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-23 05:57:50,223 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:50,615 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:51,116 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:51,280 - CompRatioSelect - INFO - Layer layer3.0.downsample.0, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-23 05:57:51,280 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:52,899 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:53,384 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:53,539 - CompRatioSelect - INFO - Layer layer3.1.conv1, comp_ratio 0.333333 ==> eval_score=92.968750\n",
      "2024-12-23 05:57:53,539 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:54,923 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:55,405 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:55,569 - CompRatioSelect - INFO - Layer layer3.1.conv1, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-23 05:57:55,570 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:56,891 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:57,451 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:57,807 - CompRatioSelect - INFO - Layer layer3.1.conv2, comp_ratio 0.333333 ==> eval_score=91.406250\n",
      "2024-12-23 05:57:57,808 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:59,281 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:57:59,784 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:57:59,942 - CompRatioSelect - INFO - Layer layer3.1.conv2, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-23 05:57:59,942 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:01,255 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:58:01,798 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 32.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:01,956 - CompRatioSelect - INFO - Layer layer4.0.conv1, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-23 05:58:01,956 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:03,625 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:58:04,132 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:04,289 - CompRatioSelect - INFO - Layer layer4.0.conv1, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-23 05:58:04,290 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:05,601 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:58:06,106 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 30.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:06,264 - CompRatioSelect - INFO - Layer layer4.0.conv2, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-23 05:58:06,265 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:07,599 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:58:08,144 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:08,305 - CompRatioSelect - INFO - Layer layer4.0.conv2, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-23 05:58:08,305 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:08,788 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:58:09,341 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:09,502 - CompRatioSelect - INFO - Layer layer4.0.downsample.0, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-23 05:58:09,503 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:10,951 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:58:11,486 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:11,656 - CompRatioSelect - INFO - Layer layer4.0.downsample.0, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-23 05:58:11,656 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:13,295 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:58:13,813 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:14,371 - CompRatioSelect - INFO - Layer layer4.1.conv1, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-23 05:58:14,372 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:16,459 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:58:16,973 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:17,130 - CompRatioSelect - INFO - Layer layer4.1.conv1, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-23 05:58:17,131 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:18,119 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:58:18,656 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:18,824 - CompRatioSelect - INFO - Layer layer4.1.conv2, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-23 05:58:18,825 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:20,656 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:58:21,171 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 34.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:21,334 - CompRatioSelect - INFO - Layer layer4.1.conv2, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-23 05:58:21,335 - CompRatioSelect - INFO - Greedy selection: Saved eval dict to ./data/greedy_selection_eval_scores_dict.pkl\n",
      "2024-12-23 05:58:21,336 - CompRatioSelect - INFO - Greedy selection: overall_min_score=90.625000, overall_max_score=96.093750\n",
      "2024-12-23 05:58:21,336 - CompRatioSelect - INFO - Greedy selection: Original model cost=(Cost: memory=11164352, mac=140186624)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:31,295 - CompRatioSelect - INFO - Greedy selection: final choice - comp_ratio=0.819081, score=92.968512\n",
      "2024-12-23 05:58:32,332 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:32,772 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 05:58:33,668 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-23 05:58:34,199 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-23 05:58:34,200 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 87.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "2024-12-23 05:58:35,692 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-23 05:58:35,693 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 103.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************************************\n",
      "Compressed Model Statistics\n",
      "Baseline model accuracy: 93.070000, Compressed model accuracy: 87.530000\n",
      "Compression ratio for memory=0.991126, mac=0.819081\n",
      "\n",
      "**********************************************************************************************\n",
      "\n",
      "Per-layer Stats\n",
      "    Name:layer1.0.conv1, compression-ratio: None\n",
      "    Name:layer1.0.conv2, compression-ratio: 0.3333333333333333333333333333\n",
      "    Name:layer1.1.conv1, compression-ratio: None\n",
      "    Name:layer1.1.conv2, compression-ratio: 0.3333333333333333333333333333\n",
      "    Name:layer2.0.conv1, compression-ratio: None\n",
      "    Name:layer2.0.conv2, compression-ratio: None\n",
      "    Name:layer2.0.downsample.0, compression-ratio: None\n",
      "    Name:layer2.1.conv1, compression-ratio: None\n",
      "    Name:layer2.1.conv2, compression-ratio: None\n",
      "    Name:layer3.0.conv1, compression-ratio: 0.6666666666666666666666666666\n",
      "    Name:layer3.0.conv2, compression-ratio: None\n",
      "    Name:layer3.0.downsample.0, compression-ratio: None\n",
      "    Name:layer3.1.conv1, compression-ratio: None\n",
      "    Name:layer3.1.conv2, compression-ratio: None\n",
      "    Name:layer4.0.conv1, compression-ratio: None\n",
      "    Name:layer4.0.conv2, compression-ratio: None\n",
      "    Name:layer4.0.downsample.0, compression-ratio: None\n",
      "    Name:layer4.1.conv1, compression-ratio: None\n",
      "    Name:layer4.1.conv2, compression-ratio: None\n",
      "\n",
      "**********************************************************************************************\n",
      "\n",
      "Greedy Eval Dict\n",
      "    Layer: layer1.0.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer1.0.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=96.09375\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.96875\n",
      "    Layer: layer1.1.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer1.1.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.96875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.96875\n",
      "    Layer: layer2.0.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer2.0.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=93.75\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=91.40625\n",
      "    Layer: layer2.0.downsample.0\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer2.1.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer2.1.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=90.625\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer3.0.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.96875\n",
      "    Layer: layer3.0.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=91.40625\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=91.40625\n",
      "    Layer: layer3.0.downsample.0\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer3.1.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.96875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer3.1.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=91.40625\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer4.0.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer4.0.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer4.0.downsample.0\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer4.1.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer4.1.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "\n",
      "**********************************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from aimet_torch.compress import ModelCompressor\n",
    "compressed_model, comp_stats = ModelCompressor.compress_model(model=model,\n",
    "                                                              eval_callback=eval_callback,\n",
    "                                                              eval_iterations=eval_iterations,\n",
    "                                                              input_shape=(1, 3, 32, 32),\n",
    "                                                              compress_scheme=compress_scheme,\n",
    "                                                              cost_metric=cost_metric,\n",
    "                                                              parameters=params)\n",
    "\n",
    "print(comp_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "2024-12-23 05:58:37,040 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-23 05:58:37,040 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 103.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = CifarDataPipeline.evaluate(compressed_model, iterations=None, use_cuda=True)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:06<00:00, 55.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:01:04,537 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-23 06:01:04,537 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 102.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval :  90.33\n",
      "2024-12-23 06:01:05,410 - Trainer - INFO - At the end of Epoch #1/10: Global Avg Loss=0.013821, Eval Accuracy=90.330000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:07<00:00, 54.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:01:12,695 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-23 06:01:12,695 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 101.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval :  90.35\n",
      "2024-12-23 06:01:13,567 - Trainer - INFO - At the end of Epoch #2/10: Global Avg Loss=0.004693, Eval Accuracy=90.350000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:07<00:00, 55.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:01:20,734 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-23 06:01:20,735 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 103.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval :  90.56\n",
      "2024-12-23 06:01:21,599 - Trainer - INFO - At the end of Epoch #3/10: Global Avg Loss=0.003127, Eval Accuracy=90.560000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:06<00:00, 56.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:01:28,666 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-23 06:01:28,666 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 104.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval :  90.42\n",
      "2024-12-23 06:01:29,529 - Trainer - INFO - At the end of Epoch #4/10: Global Avg Loss=0.002334, Eval Accuracy=90.420000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:07<00:00, 55.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:01:36,645 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:01:36,645 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 102.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval :  90.58\n",
      "2024-12-23 06:01:37,513 - Trainer - INFO - At the end of Epoch #5/10: Global Avg Loss=0.002108, Eval Accuracy=90.580000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:07<00:00, 54.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:01:44,740 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-23 06:01:44,741 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 103.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval :  90.69\n",
      "2024-12-23 06:01:45,600 - Trainer - INFO - At the end of Epoch #6/10: Global Avg Loss=0.001867, Eval Accuracy=90.690000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:07<00:00, 55.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:01:52,710 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-23 06:01:52,710 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 102.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval :  90.69\n",
      "2024-12-23 06:01:53,576 - Trainer - INFO - At the end of Epoch #7/10: Global Avg Loss=0.001915, Eval Accuracy=90.690000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:07<00:00, 55.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:02:00,718 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-23 06:02:00,718 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 103.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval :  90.68\n",
      "2024-12-23 06:02:01,587 - Trainer - INFO - At the end of Epoch #8/10: Global Avg Loss=0.001808, Eval Accuracy=90.680000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:06<00:00, 56.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:02:08,667 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-23 06:02:08,667 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 104.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval :  90.7\n",
      "2024-12-23 06:02:09,526 - Trainer - INFO - At the end of Epoch #9/10: Global Avg Loss=0.001778, Eval Accuracy=90.700000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:07<00:00, 54.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-23 06:02:16,771 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-23 06:02:16,771 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 102.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval :  90.61\n",
      "2024-12-23 06:02:17,627 - Trainer - INFO - At the end of Epoch #10/10: Global Avg Loss=0.001707, Eval Accuracy=90.610000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CifarDataPipeline.finetune(compressed_model, epochs=10, learning_rate=10e-4, learning_rate_schedule=[5, 10],\n",
    "                              use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "2024-12-23 06:02:21,009 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-23 06:02:21,010 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 102.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = CifarDataPipeline.evaluate(compressed_model, iterations=None, use_cuda=True)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./output/', exist_ok=True)\n",
    "torch.save(compressed_model, './output/finetuned_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
