{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets.folder import default_loader, has_file_allowed_extension\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data as torch_data\n",
    "\n",
    "\n",
    "class CifarDataLoader:\n",
    "    \"\"\"\n",
    "    For loading Validation data from the ImageNet dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_size: int=32, batch_size: int = 128,\n",
    "                 is_training: bool = False, num_workers: int = 2, num_samples_per_class: int = None):\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            # transforms.RandomHorizontalFlip(),\n",
    "            # transforms.RandomCrop(32, padding=4),\n",
    "            transforms.Resize((32,32)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616))\n",
    "        ])\n",
    "        if is_training:\n",
    "            trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "            self._data_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "        else:\n",
    "            testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "            self._data_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    @property\n",
    "    def data_loader(self) -> torch_data.DataLoader:\n",
    "        \"\"\"\n",
    "        Returns the data-loader\n",
    "        \"\"\"\n",
    "        return self._data_loader\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_loader)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from Examples.common.utils import accuracy\n",
    "# from Examples.torch.utils.image_net_data_loader import ImageNetDataLoader\n",
    "\n",
    "logger = logging.getLogger('Eval')\n",
    "\n",
    "\n",
    "class CifarEvaluator:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._val_data_loader = CifarDataLoader(is_training=False).data_loader\n",
    "\n",
    "    def evaluate(self, model: nn.Module, iterations: int = None, use_cuda: bool = False) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the specified model using the specified number of samples batches from the\n",
    "        validation set.\n",
    "        :param model: The model to be evaluated.\n",
    "        :param iterations: The number of batches to use from the validation set.\n",
    "        :param use_cuda: If True then use a GPU for inference.\n",
    "        :return: The accuracy for the sample with the maximum accuracy.\n",
    "        \"\"\"\n",
    "\n",
    "        device = torch.device('cpu')\n",
    "        if use_cuda:\n",
    "            if torch.cuda.is_available():\n",
    "                \"here\"\n",
    "                device = torch.device('cuda')\n",
    "            else:\n",
    "                logger.error('use_cuda is selected but no cuda device found.')\n",
    "                raise RuntimeError(\"Found no CUDA Device while use_cuda is selected\")\n",
    "\n",
    "        if iterations is None:\n",
    "            logger.info('No value of iteration is provided, running evaluation on complete dataset.')\n",
    "            iterations = len(self._val_data_loader)\n",
    "        if iterations <= 0:\n",
    "            logger.error('Cannot evaluate on %d iterations', iterations)\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        logger.info(\"Evaluating nn.Module for %d iterations with batch_size %d\",\n",
    "                    iterations, self._val_data_loader.batch_size)\n",
    "\n",
    "        model = model.to(device)\n",
    "        model = model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (input_data, target_data) in tqdm(enumerate(self._val_data_loader), total=iterations):\n",
    "                if i == iterations:\n",
    "                    break\n",
    "\n",
    "                inputs_batch = input_data.to(device)\n",
    "                target_batch = target_data.to(device)\n",
    "                predicted_batch = model(inputs_batch)\n",
    "                _, predicted = predicted_batch.max(1)\n",
    "                total += target_batch.size(0)\n",
    "                correct += predicted.eq(target_batch).sum().item()\n",
    "\n",
    "        return 100 * correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "logger = logging.getLogger('Trainer')\n",
    "\n",
    "\n",
    "class CifarTrainer:\n",
    "    \"\"\"\n",
    "    For training a model using the ImageNet dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    # pylint: disable=too-many-arguments\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        :param images_dir: The path to the data directory\n",
    "        :param image_size: The length of the image\n",
    "        :param batch_size: The batch size to use for training and validation\n",
    "        :param num_workers: Indiicates to the data loader how many sub-processes to use for data loading.\n",
    "        :param num_train_samples_per_class: Number of samples to use per class.\n",
    "        \"\"\"\n",
    "\n",
    "        self._train_loader = CifarDataLoader(is_training=True).data_loader\n",
    "\n",
    "        self._evaluator = CifarEvaluator()\n",
    "\n",
    "    def _train_loop(self, model: nn.Module, criterion: torch.nn.modules.loss, optimizer: torch.optim,\n",
    "                    max_iterations: int, current_epoch: int, max_epochs: int,\n",
    "                    debug_steps: int = 1000, use_cuda: bool = False):\n",
    "        \"\"\"\n",
    "        Train the specified model using the ImageNet dataset for one epoch.\n",
    "        :param model: The model to train.\n",
    "        :param criterion: loss function to optimize\n",
    "        :param optimizer: optimizer function\n",
    "        :param max_iterations: total number of iterations to train\n",
    "        :param current_epoch: current epoch for model training, used for reporting logs in debug steps\n",
    "        :param max_epochs: total epoch for model training, used for reporting logs in debug steps\n",
    "        :param debug_steps: number of training iterations to report accuracy/loss metrics\n",
    "        :param use_cuda: If True then use GPU device\n",
    "\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # pylint: disable-msg=too-many-locals\n",
    "        device = torch.device('cpu')\n",
    "        if use_cuda:\n",
    "            if torch.cuda.is_available():\n",
    "                device = torch.device('cuda')\n",
    "            else:\n",
    "                logger.error('use_cuda is selected but no cuda device found.')\n",
    "                raise RuntimeError(\"Found no CUDA Device while use_cuda is selected\")\n",
    "\n",
    "        # switch to training mode\n",
    "        model = model.to(device)\n",
    "        model.train()\n",
    "\n",
    "        avg_loss = 0.0\n",
    "\n",
    "        for i, (images, target) in tqdm(enumerate(self._train_loader), total=max_iterations):\n",
    "            if i == max_iterations:\n",
    "                break\n",
    "\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # compute model output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            avg_loss += loss.item()\n",
    "\n",
    "            # compute gradient and do SGD step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % debug_steps == 0:\n",
    "                eval_accuracy = self._evaluator.evaluate(model, use_cuda=use_cuda)\n",
    "                logger.info('Epoch #%d/%d: iteration #%d/%d: Global Avg Loss=%f, Eval Accuracy=%f',\n",
    "                            current_epoch, max_epochs, i, max_iterations,\n",
    "                            avg_loss / i, eval_accuracy)\n",
    "                # switch to training mode after evaluation\n",
    "                model.train()\n",
    "\n",
    "        eval_accuracy = self._evaluator.evaluate(model, use_cuda=use_cuda)\n",
    "        print(\"eval : \", eval_accuracy)\n",
    "        logger.info('At the end of Epoch #%d/%d: Global Avg Loss=%f, Eval Accuracy=%f',\n",
    "                    current_epoch, max_epochs, avg_loss / max_iterations, eval_accuracy)\n",
    "\n",
    "    def train(self, model: nn.Module, max_epochs: int = 20, learning_rate: int = 0.1,\n",
    "              weight_decay: float = 1e-4, decay_rate: float = 0.1, learning_rate_schedule: list = None,\n",
    "              debug_steps: int = 1000, use_cuda: bool = False):\n",
    "        \"\"\"\n",
    "        Train the specified model using the ImageNet dataset.\n",
    "        :param model: The model to train.\n",
    "        :param max_epochs: Maximum number of epochs to use in training.\n",
    "        :param learning_rate: Learning rate\n",
    "        :param weight_decay: Weight decay\n",
    "        :param decay_rate: Multiplicative factor of learning rate decay\n",
    "        :param learning_rate_schedule: Adjust the learning rate based on the number of epochs\n",
    "        :param debug_steps: number of training iterations to report accuracy/loss metrics\n",
    "        :param use_cuda: If True then use GPU device\n",
    "\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        max_iterations = len(self._train_loader)\n",
    "\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay)\n",
    "\n",
    "        if learning_rate_schedule:\n",
    "            learning_rate_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, learning_rate_schedule,\n",
    "                                                                     gamma=decay_rate)\n",
    "\n",
    "        for current_epoch in range(max_epochs):\n",
    "            self._train_loop(model, loss, optimizer, max_iterations, current_epoch + 1, max_epochs, debug_steps,\n",
    "                             use_cuda)\n",
    "\n",
    "            if learning_rate_schedule:\n",
    "                learning_rate_scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from typing import List\n",
    "\n",
    "class CifarDataPipeline:\n",
    "\n",
    "    @staticmethod\n",
    "    def get_val_dataloader() -> torch.utils.data.DataLoader:\n",
    "\n",
    "        data_loader = CifarDataLoader()\n",
    "        return data_loader\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate(model: torch.nn.Module, iterations: int, use_cuda: bool) -> float:\n",
    "        \"\"\"\n",
    "        Given a torch model, evaluates its Top-1 accuracy on the dataset\n",
    "        :param model: the model to evaluate\n",
    "        :param iterations: the number of batches to be used to evaluate the model. A value of 'None' means the model will be\n",
    "                           evaluated on the entire dataset once.\n",
    "        :param use_cuda: whether or not the GPU should be used.\n",
    "        \"\"\"\n",
    "        evaluator = CifarEvaluator()\n",
    "\n",
    "        return evaluator.evaluate(model, iterations=iterations, use_cuda=use_cuda)\n",
    "\n",
    "    @staticmethod\n",
    "    def finetune(model: torch.nn.Module, epochs: int, learning_rate: float, learning_rate_schedule: List, use_cuda: bool):\n",
    "        \"\"\"\n",
    "        Given a torch model, finetunes the model to improve its accuracy\n",
    "        :param model: the model to finetune\n",
    "        :param epochs: The number of epochs used during the finetuning step.\n",
    "        :param learning_rate: The learning rate used during the finetuning step.\n",
    "        :param learning_rate_schedule: The learning rate schedule used during the finetuning step.\n",
    "        :param use_cuda: whether or not the GPU should be used.\n",
    "        \"\"\"\n",
    "        trainer = CifarTrainer()\n",
    "\n",
    "        trainer.train(model, max_epochs=epochs, learning_rate=learning_rate,\n",
    "                      learning_rate_schedule=learning_rate_schedule, use_cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar10_models.resnet import resnet18\n",
    "model = resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 84.10it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = CifarDataPipeline.evaluate(model, iterations=None, use_cuda=True)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from decimal import Decimal\n",
    "from aimet_torch.defs import GreedySelectionParameters, ChannelPruningParameters\n",
    "from aimet_common.defs import CompressionScheme, CostMetric\n",
    "\n",
    "greedy_params = GreedySelectionParameters(target_comp_ratio=Decimal(0.9),\n",
    "                                          num_comp_ratio_candidates=3)\n",
    "modules_to_ignore = [model.conv1]\n",
    "auto_params = ChannelPruningParameters.AutoModeParams(greedy_select_params=greedy_params,\n",
    "                                                      modules_to_ignore=modules_to_ignore)\n",
    "data_loader = CifarDataPipeline.get_val_dataloader()\n",
    "params = ChannelPruningParameters(data_loader=data_loader,\n",
    "                                  num_reconstruction_samples=10,\n",
    "                                  allow_custom_downsample_ops=False,\n",
    "                                  mode=ChannelPruningParameters.Mode.auto,\n",
    "                                  params=auto_params)\n",
    "\n",
    "eval_callback = CifarDataPipeline.evaluate\n",
    "eval_iterations = 1\n",
    "compress_scheme = CompressionScheme.channel_pruning\n",
    "cost_metric = CostMetric.mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:03,848 - root - INFO - AIMET\n"
     ]
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.2.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.2.min.js\", \"https://cdn.holoviz.org/panel/1.3.8/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1002'>\n",
       "  <div id=\"f02f4d35-5e0a-4d92-8163-b6328f60d58d\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"2d2ce1ba-2598-4b01-b1ea-fbefa42b0ae6\":{\"version\":\"3.2.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1002\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1003\",\"attributes\":{\"plot_id\":\"p1002\",\"comm_id\":\"81c13f64f12748038c306a96d3e17e6c\",\"client_comm_id\":\"4517649df267414e85e0d2ac182eaefd\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"2d2ce1ba-2598-4b01-b1ea-fbefa42b0ae6\",\"roots\":{\"p1002\":\"f02f4d35-5e0a-4d92-8163-b6328f60d58d\"},\"root_ids\":[\"p1002\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1002"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:08,662 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:10,246 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:10,731 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 30.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:10,864 - CompRatioSelect - INFO - Layer layer1.0.conv1, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:10,865 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:11,305 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:11,799 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:11,935 - CompRatioSelect - INFO - Layer layer1.0.conv1, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:11,936 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:12,494 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:12,979 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 31.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:13,127 - CompRatioSelect - INFO - Layer layer1.0.conv2, comp_ratio 0.333333 ==> eval_score=92.968750\n",
      "2024-12-22 11:01:13,128 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:13,527 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:14,011 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:14,159 - CompRatioSelect - INFO - Layer layer1.0.conv2, comp_ratio 0.666667 ==> eval_score=92.968750\n",
      "2024-12-22 11:01:14,160 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:14,599 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:15,083 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:15,227 - CompRatioSelect - INFO - Layer layer1.1.conv1, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:15,228 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:15,677 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:16,160 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:16,319 - CompRatioSelect - INFO - Layer layer1.1.conv1, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:16,320 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:16,705 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:17,229 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:17,380 - CompRatioSelect - INFO - Layer layer1.1.conv2, comp_ratio 0.333333 ==> eval_score=92.968750\n",
      "2024-12-22 11:01:17,381 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:17,787 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:18,277 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:18,431 - CompRatioSelect - INFO - Layer layer1.1.conv2, comp_ratio 0.666667 ==> eval_score=92.968750\n",
      "2024-12-22 11:01:18,431 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:18,897 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:19,393 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:19,538 - CompRatioSelect - INFO - Layer layer2.0.conv1, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:19,538 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:20,003 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:20,502 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:20,646 - CompRatioSelect - INFO - Layer layer2.0.conv1, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:20,646 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:21,144 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:21,652 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:21,802 - CompRatioSelect - INFO - Layer layer2.0.conv2, comp_ratio 0.333333 ==> eval_score=91.406250\n",
      "2024-12-22 11:01:21,802 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:22,344 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:22,843 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:22,994 - CompRatioSelect - INFO - Layer layer2.0.conv2, comp_ratio 0.666667 ==> eval_score=93.750000\n",
      "2024-12-22 11:01:22,995 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:23,359 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:23,846 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:23,993 - CompRatioSelect - INFO - Layer layer2.0.downsample.0, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:23,994 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:24,357 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:24,838 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:24,994 - CompRatioSelect - INFO - Layer layer2.0.downsample.0, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:24,995 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:25,646 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:26,138 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:26,291 - CompRatioSelect - INFO - Layer layer2.1.conv1, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:26,292 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:26,931 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:27,444 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:27,594 - CompRatioSelect - INFO - Layer layer2.1.conv1, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:27,595 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:28,023 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:28,528 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:28,681 - CompRatioSelect - INFO - Layer layer2.1.conv2, comp_ratio 0.333333 ==> eval_score=89.062500\n",
      "2024-12-22 11:01:28,681 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:29,248 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:29,761 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:29,911 - CompRatioSelect - INFO - Layer layer2.1.conv2, comp_ratio 0.666667 ==> eval_score=92.968750\n",
      "2024-12-22 11:01:29,912 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:30,608 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:31,111 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:31,268 - CompRatioSelect - INFO - Layer layer3.0.conv1, comp_ratio 0.333333 ==> eval_score=91.406250\n",
      "2024-12-22 11:01:31,268 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:31,936 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:32,440 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:32,600 - CompRatioSelect - INFO - Layer layer3.0.conv1, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:32,601 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:33,192 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:33,693 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:33,853 - CompRatioSelect - INFO - Layer layer3.0.conv2, comp_ratio 0.333333 ==> eval_score=90.625000\n",
      "2024-12-22 11:01:33,854 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:34,773 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:35,258 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:35,403 - CompRatioSelect - INFO - Layer layer3.0.conv2, comp_ratio 0.666667 ==> eval_score=92.968750\n",
      "2024-12-22 11:01:35,404 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:35,782 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:36,271 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:36,429 - CompRatioSelect - INFO - Layer layer3.0.downsample.0, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:36,430 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:36,802 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:37,293 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:37,452 - CompRatioSelect - INFO - Layer layer3.0.downsample.0, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:37,452 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:38,410 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:38,871 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:39,021 - CompRatioSelect - INFO - Layer layer3.1.conv1, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:39,022 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:39,977 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:40,443 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:40,593 - CompRatioSelect - INFO - Layer layer3.1.conv1, comp_ratio 0.666667 ==> eval_score=92.968750\n",
      "2024-12-22 11:01:40,594 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:41,185 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:41,683 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:41,842 - CompRatioSelect - INFO - Layer layer3.1.conv2, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:41,842 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:42,623 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:43,108 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:43,263 - CompRatioSelect - INFO - Layer layer3.1.conv2, comp_ratio 0.666667 ==> eval_score=91.406250\n",
      "2024-12-22 11:01:43,264 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:44,190 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:44,685 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:44,840 - CompRatioSelect - INFO - Layer layer4.0.conv1, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:44,840 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:46,059 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:46,549 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:46,698 - CompRatioSelect - INFO - Layer layer4.0.conv1, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:46,699 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:47,449 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:47,931 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:48,091 - CompRatioSelect - INFO - Layer layer4.0.conv2, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:48,092 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:49,698 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:50,194 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:50,344 - CompRatioSelect - INFO - Layer layer4.0.conv2, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:50,345 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:50,795 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:51,299 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:51,460 - CompRatioSelect - INFO - Layer layer4.0.downsample.0, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:51,461 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:51,900 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:52,406 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 27.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:52,569 - CompRatioSelect - INFO - Layer layer4.0.downsample.0, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:52,570 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:54,017 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:54,513 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:54,669 - CompRatioSelect - INFO - Layer layer4.1.conv1, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:54,670 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:56,092 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:56,596 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:56,753 - CompRatioSelect - INFO - Layer layer4.1.conv1, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:56,754 - CompRatioSelect - INFO - Analyzing compression ratio: 0.3333333333333333333333333333 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:57,744 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:58,226 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:58,386 - CompRatioSelect - INFO - Layer layer4.1.conv2, comp_ratio 0.333333 ==> eval_score=92.187500\n",
      "2024-12-22 11:01:58,386 - CompRatioSelect - INFO - Analyzing compression ratio: 0.6666666666666666666666666666 =====================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:01:59,470 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:01:59,966 - Trainer - INFO - Evaluating nn.Module for 1 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 28.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:02:00,117 - CompRatioSelect - INFO - Layer layer4.1.conv2, comp_ratio 0.666667 ==> eval_score=92.187500\n",
      "2024-12-22 11:02:00,118 - CompRatioSelect - INFO - Greedy selection: Saved eval dict to ./data/greedy_selection_eval_scores_dict.pkl\n",
      "2024-12-22 11:02:00,119 - CompRatioSelect - INFO - Greedy selection: overall_min_score=89.062500, overall_max_score=93.750000\n",
      "2024-12-22 11:02:00,119 - CompRatioSelect - INFO - Greedy selection: Original model cost=(Cost: memory=11164352, mac=140186624)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:02:11,985 - CompRatioSelect - INFO - Greedy selection: final choice - comp_ratio=0.706007, score=92.968655\n",
      "2024-12-22 11:02:12,386 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:02:12,808 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:02:13,415 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:02:14,222 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n",
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/winnow_utils.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  result = torch.tensor(tensor)  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:02:15,060 - ChannelPruning - INFO - finished linear regression fit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/aimet_torch/winnow/mask_propagation_winnower.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dummy_input = torch.tensor(dummy_input).cuda()  # pylint: disable=not-callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:02:16,115 - ChannelPruning - INFO - finished linear regression fit \n",
      "Files already downloaded and verified\n",
      "2024-12-22 11:02:16,576 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-22 11:02:16,576 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 105.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "2024-12-22 11:02:17,892 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-22 11:02:17,893 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 102.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************************************\n",
      "Compressed Model Statistics\n",
      "Baseline model accuracy: 93.070000, Compressed model accuracy: 82.880000\n",
      "Compression ratio for memory=0.948975, mac=0.706007\n",
      "\n",
      "**********************************************************************************************\n",
      "\n",
      "Per-layer Stats\n",
      "    Name:layer1.0.conv1, compression-ratio: None\n",
      "    Name:layer1.0.conv2, compression-ratio: 0.3333333333333333333333333333\n",
      "    Name:layer1.1.conv1, compression-ratio: None\n",
      "    Name:layer1.1.conv2, compression-ratio: 0.3333333333333333333333333333\n",
      "    Name:layer2.0.conv1, compression-ratio: None\n",
      "    Name:layer2.0.conv2, compression-ratio: 0.6666666666666666666666666666\n",
      "    Name:layer2.0.downsample.0, compression-ratio: None\n",
      "    Name:layer2.1.conv1, compression-ratio: None\n",
      "    Name:layer2.1.conv2, compression-ratio: 0.6666666666666666666666666666\n",
      "    Name:layer3.0.conv1, compression-ratio: None\n",
      "    Name:layer3.0.conv2, compression-ratio: 0.6666666666666666666666666666\n",
      "    Name:layer3.0.downsample.0, compression-ratio: None\n",
      "    Name:layer3.1.conv1, compression-ratio: 0.6666666666666666666666666666\n",
      "    Name:layer3.1.conv2, compression-ratio: None\n",
      "    Name:layer4.0.conv1, compression-ratio: None\n",
      "    Name:layer4.0.conv2, compression-ratio: None\n",
      "    Name:layer4.0.downsample.0, compression-ratio: None\n",
      "    Name:layer4.1.conv1, compression-ratio: None\n",
      "    Name:layer4.1.conv2, compression-ratio: None\n",
      "\n",
      "**********************************************************************************************\n",
      "\n",
      "Greedy Eval Dict\n",
      "    Layer: layer1.0.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer1.0.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.96875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.96875\n",
      "    Layer: layer1.1.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer1.1.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.96875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.96875\n",
      "    Layer: layer2.0.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer2.0.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=91.40625\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=93.75\n",
      "    Layer: layer2.0.downsample.0\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer2.1.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer2.1.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=89.0625\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.96875\n",
      "    Layer: layer3.0.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=91.40625\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer3.0.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=90.625\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.96875\n",
      "    Layer: layer3.0.downsample.0\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer3.1.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.96875\n",
      "    Layer: layer3.1.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=91.40625\n",
      "    Layer: layer4.0.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer4.0.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer4.0.downsample.0\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer4.1.conv1\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "    Layer: layer4.1.conv2\n",
      "        Ratio=0.3333333333333333333333333333, Eval score=92.1875\n",
      "        Ratio=0.6666666666666666666666666666, Eval score=92.1875\n",
      "\n",
      "**********************************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from aimet_torch.compress import ModelCompressor\n",
    "compressed_model, comp_stats = ModelCompressor.compress_model(model=model,\n",
    "                                                              eval_callback=eval_callback,\n",
    "                                                              eval_iterations=eval_iterations,\n",
    "                                                              input_shape=(1, 3, 32, 32),\n",
    "                                                              compress_scheme=compress_scheme,\n",
    "                                                              cost_metric=cost_metric,\n",
    "                                                              parameters=params)\n",
    "\n",
    "print(comp_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "2024-12-22 10:56:41,792 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-22 10:56:41,792 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 71.82it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = CifarDataPipeline.evaluate(compressed_model, iterations=None, use_cuda=True)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 52.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:03:25,607 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-22 11:03:25,607 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 102.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval :  82.76\n",
      "2024-12-22 11:03:26,490 - Trainer - INFO - At the end of Epoch #1/5: Global Avg Loss=0.222520, Eval Accuracy=82.760000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:07<00:00, 51.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:03:34,174 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-22 11:03:34,175 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 103.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval :  86.81\n",
      "2024-12-22 11:03:35,041 - Trainer - INFO - At the end of Epoch #2/5: Global Avg Loss=0.161487, Eval Accuracy=86.810000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:07<00:00, 51.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:03:42,690 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-22 11:03:42,691 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 101.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval :  86.28\n",
      "2024-12-22 11:03:43,566 - Trainer - INFO - At the end of Epoch #3/5: Global Avg Loss=0.116326, Eval Accuracy=86.280000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:07<00:00, 53.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:03:51,023 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-22 11:03:51,024 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 103.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval :  86.14\n",
      "2024-12-22 11:03:51,884 - Trainer - INFO - At the end of Epoch #4/5: Global Avg Loss=0.089073, Eval Accuracy=86.140000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 391/391 [00:07<00:00, 51.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 11:03:59,591 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-22 11:03:59,591 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 79/79 [00:00<00:00, 102.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval :  86.38\n",
      "2024-12-22 11:04:00,458 - Trainer - INFO - At the end of Epoch #5/5: Global Avg Loss=0.067195, Eval Accuracy=86.380000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CifarDataPipeline.finetune(compressed_model, epochs=5, learning_rate=15e-4, learning_rate_schedule=[5, 10],\n",
    "                              use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "2024-12-22 11:04:04,041 - Trainer - INFO - No value of iteration is provided, running evaluation on complete dataset.\n",
      "2024-12-22 11:04:04,042 - Trainer - INFO - Evaluating nn.Module for 79 iterations with batch_size 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 101.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = CifarDataPipeline.evaluate(compressed_model, iterations=None, use_cuda=True)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./output/', exist_ok=True)\n",
    "torch.save(compressed_model, './output/finetuned_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
